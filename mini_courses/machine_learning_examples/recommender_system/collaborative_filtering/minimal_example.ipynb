{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "1. Need to remove timestamps\n",
    "2. move ids are not consecutive, so we need to make them consecutive.\n",
    "3. user IDs are not starting from 0. Need to make it 1.\n",
    "4. Then, make a \"very small data set\" from the most common K users & movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import inspect\n",
    "import pandas as pd\n",
    "\n",
    "# currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "currentdir = %pwd\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0, parentdir)\n",
    "\n",
    "# Define the path to the CSV file\n",
    "csv_path = parentdir+'/movielens_20/rating.csv'\n",
    "movie_lens_path = parentdir+\"/movielens_20\"\n",
    "edited_csv_path = movie_lens_path + \"/edited_rating.csv\"\n",
    "\n",
    "if os.path.exists(edited_csv_path):\n",
    "    print(f'Reading edited csv')\n",
    "    df = pd.read_csv(edited_csv_path)\n",
    "    print(f'Successfully read edited csv')\n",
    "else:\n",
    "    print(f\"creating edited csv\")\n",
    "    # might take a while\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df = df.drop(\"timestamp\", axis=1)\n",
    "\n",
    "    # reassign movie id\n",
    "    movie_ids = set(df.movieId)\n",
    "    movie_id_lookup = {}\n",
    "    for i, movie_id in enumerate(movie_ids):\n",
    "        movie_id_lookup[movie_id] = i\n",
    "    # This might take a while\n",
    "    df[\"movieId\"] = df.apply(lambda row: movie_id_lookup[row.movieId], axis = 1)\n",
    "    df.userId = df.userId - 1\n",
    "    df.to_csv(edited_csv_path)\n",
    "    print(f'Successfully generated edited csv')\n",
    "\n",
    "\n",
    "small_edited_csv_path = parentdir+\"/movielens_20/small_edited_rating.csv\"\n",
    "if os.path.exists(small_edited_csv_path):\n",
    "    print(f'reading small csv for training and testing')\n",
    "    small_df = pd.read_csv(small_edited_csv_path)\n",
    "else:\n",
    "    print(f'generating small csv for training and testing')\n",
    "    from collections import Counter\n",
    "    user_counts = Counter(df.userId)\n",
    "    movie_counts = Counter(df.movieId)\n",
    "    common_user_ids = [u for u, c in user_counts.most_common(100)]\n",
    "    common_movie_ids = [m for m, c in movie_counts.most_common(20)]\n",
    "\n",
    "    # Carve the data out\n",
    "    # df also by default does not create copies. \n",
    "    small_df = df[df.userId.isin(common_user_ids) & df.movieId.isin(common_movie_ids)].copy()\n",
    "    # remap movie and user IDs\n",
    "\n",
    "    def remap_to_consecutive_numbers(df, cln_name):\n",
    "        df_cln = df[cln_name]\n",
    "        unique_cln = set(df_cln)\n",
    "        lookup = {}\n",
    "        for i, old_id in enumerate(unique_cln):\n",
    "            lookup[old_id] = i\n",
    "        # WEIRD: must use df[cln_name] instead of df_cln\n",
    "        # This might take a while\n",
    "        df[cln_name] = df.apply(lambda row: lookup[row[cln_name]], axis = 1)\n",
    "        return lookup\n",
    "\n",
    "    remap_to_consecutive_numbers(small_df, \"userId\")\n",
    "    remap_to_consecutive_numbers(small_df, \"movieId\")\n",
    "    small_df.to_csv(small_edited_csv_path)\n",
    "print(f'small df loaded')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runtime Behaviors\n",
    "1. From very small data set, split rows/columns into trainin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "\n",
    "\n",
    "user2movies_path = parentdir+\"/movielens_20/user2movies.pkl\"\n",
    "movies2user_path = parentdir+\"/movielens_20/movies2user.pkl\"\n",
    "ratings_path = parentdir+\"/movielens_20/ratings.pkl\"\n",
    "train_df_path = parentdir+\"/movielens_20/train_df.csv\"\n",
    "test_df_path = parentdir+\"/movielens_20/test_df.csv\"\n",
    "\n",
    "DIVIDE_DATA = False\n",
    "for path in (user2movies_path, movies2user_path, ratings_path, train_df_path, test_df_path):\n",
    "    if not os.path.exists(path):\n",
    "        DIVIDE_DATA = True\n",
    "        break\n",
    "\n",
    "if DIVIDE_DATA:\n",
    "    #TODO Remember to remove\n",
    "    print(f'Dividing and saving data ...')\n",
    "    small_df = shuffle(small_df)\n",
    "    TEST_PERCENTAGE = 0.8\n",
    "    cutoff = int(len(small_df) * TEST_PERCENTAGE)\n",
    "    train_df = small_df.iloc[:cutoff]\n",
    "    test_df = small_df.iloc[cutoff:]\n",
    "    user2movies = defaultdict(lambda: set())\n",
    "    movies2user = defaultdict(lambda: set())\n",
    "    ratings = {}\n",
    "    # use apply, it's faster\n",
    "    def update_mapping(row):\n",
    "        user_id = int(row.userId)\n",
    "        movie_id = int(row.movieId)\n",
    "        user2movies[user_id].add(movie_id)\n",
    "        movies2user[movie_id].add(user_id)\n",
    "        key = (int(row.userId), int(row.movieId))\n",
    "        ratings[key] = row.rating\n",
    "    train_df.apply(update_mapping, axis=1)\n",
    "\n",
    "    with open(user2movies_path, \"wb\") as f:\n",
    "        pickle.dump(dict(user2movies), f)\n",
    "    with open(movies2user_path, \"wb\") as f:\n",
    "        pickle.dump(dict(movies2user), f)\n",
    "    with open(ratings_path, \"wb\") as f:\n",
    "        pickle.dump(dict(ratings), f)\n",
    "    train_df.to_csv(train_df_path)\n",
    "    test_df.to_csv(test_df_path)\n",
    "else:\n",
    "    #TODO Remember to remove\n",
    "    print(f'Loading training and test data ... ')\n",
    "    with open(user2movies_path, \"rb\") as f:\n",
    "        user2movies = pickle.load(f)\n",
    "    with open(movies2user_path, \"rb\") as f:\n",
    "        movies2user = pickle.load(f)\n",
    "    with open(ratings_path, \"rb\") as f:\n",
    "        ratings = pickle.load(f)\n",
    "    train_df = pd.read_csv(train_df_path)\n",
    "    test_df = pd.read_csv(test_df_path)\n",
    "#TODO Remember to remove\n",
    "print(f'Training and testing data loaded')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "import numpy as np\n",
    "from typing import Set\n",
    "import heapq\n",
    "import time\n",
    "\n",
    "NEIGHBOR_NUM = 25\n",
    "# threshold on number of movies for neightbors\n",
    "COMMON_MOVIE_THRE = 5\n",
    "DEBUG_USER_THRE = 3\n",
    "Weight = namedtuple(\"Weight\",[\"value\", \"name\"])\n",
    "\n",
    "class User2UserTraining:\n",
    "    def __init__(self):\n",
    "        print(f'Loading Training model')\n",
    "        self.training_results_path = os.path.join(movie_lens_path, \"user2user_training_results.pkl\")\n",
    "        self.training_results_index = 1\n",
    "        self.debug_count = 0\n",
    "        self.loaded_objs = []\n",
    "\n",
    "    def initialize_model(self):\n",
    "        for i in range(self.training_results_index, 0, -1):\n",
    "            training_results_path = self.training_results_path + \".\" + str(i)\n",
    "            with open(training_results_path, \"rb\") as f:\n",
    "                while True:\n",
    "                    try:\n",
    "                        self.loaded_objs.append(pickle.load(f))\n",
    "                    except EOFError:\n",
    "                        break \n",
    "            \n",
    "            if self.loaded_objs:\n",
    "                self.weight_heapqs, self.means, self.stds, self.movie_devs, self.compared = self.loaded_objs\n",
    "                print(f'Training model loaded successfully, from {training_results_path}')\n",
    "                return \n",
    "\n",
    "        # User data are stored in lists, because the indices have been normalized\n",
    "        self.weight_heapqs = [[Weight(float('-inf'), \"\") for _ in range(NEIGHBOR_NUM)] for _ in range (len(user2movies))] \n",
    "        self.means = [float('-inf') for _ in range (len(user2movies))] \n",
    "        self.stds = [float('-inf') for _ in range (len(user2movies))] \n",
    "        # deviations of each user. A movie deviation is rating - mean\n",
    "        self.movie_devs = [{} for _ in range (len(user2movies))]\n",
    "        # set that stores frozenset(user_i, user_i')\n",
    "        self.compared = set()\n",
    "        print(f'No training model found, initialized model objects')\n",
    "\n",
    "    def save_model(self):\n",
    "        \"\"\"\n",
    "        Save the model to different files: PATH.0, PATH.1\n",
    "        \"\"\"\n",
    "        if self.training_results_index % 2 == 0:\n",
    "            self.training_results_index = 0\n",
    "        training_results_path = self.training_results_path+\".\"+str(self.training_results_index)\n",
    "        with open(training_results_path, \"wb\") as f:\n",
    "            for obj in self.weight_heapqs, self.means, self.stds, self.movie_devs, self.compared:\n",
    "                pickle.dump(obj, f)\n",
    "        self.training_results_index += 1  \n",
    "\n",
    "    def get_and_update_mean_std(self,user: int, movies: Set[int]):\n",
    "        \"\"\"Update means and stds, and return them. Nice\"\"\"\n",
    "        if self.means[user] == float('-inf') or self.stds[user] != float('-inf'):\n",
    "            user_all_ratings = np.array([\n",
    "                ratings[(int(user), int(movie_id))] for movie_id in movies])\n",
    "            self.means[user] = np.mean(user_all_ratings)\n",
    "            # standard deviation of all user ratings\n",
    "            self.stds[user] = np.std(user_all_ratings)\n",
    "        return self.means[user], self.stds[user]\n",
    "\n",
    "    def get_and_update_movie_devs(self, mean: int, user: int, movies: Set[int]):\n",
    "        \"\"\"Update movie deviations for a single user. A movie deviation is rating - mean\"\"\"\n",
    "        if not self.movie_devs[user]:\n",
    "            user_all_ratings = np.array([\n",
    "                ratings[(int(user), int(movie_id))] for movie_id in movies])\n",
    "            dev_ratings = user_all_ratings - mean\n",
    "            self.movie_devs[user] = {movie: dev_rating for movie, dev_rating in zip(movies, dev_ratings)}\n",
    "        return self.movie_devs[user]\n",
    "\n",
    "    def has_been_trained(self, user: int):\n",
    "        \"\"\"\n",
    "        We are using self.movie_devs to check if a user's model has been trained. \n",
    "        Since the kernel might be killed accidentally, this function might return true on the last user that kernel broke. \n",
    "        But technically, that should be only one user.\n",
    "        \"\"\"\n",
    "        if self.movie_devs[user]:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def train(self):\n",
    "        start_time = time.perf_counter()\n",
    "        for user, movies in user2movies.items():\n",
    "            if self.debug_count % 10 == 0:\n",
    "                self.save_model()\n",
    "                print(f\"User count: {self.debug_count}, time elapsed: {time.perf_counter() - start_time}s\")\n",
    "            self.debug_count += 1\n",
    "            if self.has_been_trained(user):\n",
    "                continue\n",
    "            mean, std = self.get_and_update_mean_std(user, movies)\n",
    "            movie_devs_dict = self.get_and_update_movie_devs(mean, user, movies)\n",
    "            for movie_id in movies:\n",
    "                other_users = movies2user[movie_id]\n",
    "                for another_user in other_users:\n",
    "                    # See if we have compared \n",
    "                    key_compared = frozenset((user, another_user))\n",
    "                    if key_compared in self.compared:\n",
    "                        continue\n",
    "                    self.compared.add(key_compared)\n",
    "                    another_user_movies = user2movies[another_user]\n",
    "                    common_movies = movies & another_user_movies\n",
    "\n",
    "                    if len(common_movies) < COMMON_MOVIE_THRE:\n",
    "                        continue\n",
    "\n",
    "                    if another_user == user:\n",
    "                        continue \n",
    "                    # calculate weight: \n",
    "                    # HACK: we are calculating weights using the stds and movie_devs of all users' movies, instead of the common ones\n",
    "                    # Then, a weight is calculated by multiplying sums of deviations of the common movies\n",
    "                    # That's been tested fine in production. So, this may not work great if the common movie's std deviations are drastically\n",
    "                    # different from the two users over standard deviation \n",
    "                    another_mean, another_std = self.get_and_update_mean_std(another_user, another_user_movies)\n",
    "                    another_movie_devs_dict = self.get_and_update_movie_devs(another_mean, another_user, another_user_movies)\n",
    "                    numerator = sum([movie_devs_dict[m] * another_movie_devs_dict[m] for m in common_movies])/len(common_movies)\n",
    "                    denominator = another_std * std\n",
    "\n",
    "                    if denominator != 0.0:\n",
    "                        w_ij = numerator/denominator\n",
    "\n",
    "                    # add to heapque\n",
    "                    heapq.heappushpop(self.weight_heapqs[user], Weight(w_ij, another_user))\n",
    "                    heapq.heappushpop(self.weight_heapqs[another_user], Weight(w_ij, user))\n",
    "\n",
    "    def _predict(self, user_id: int, movie_id: int):\n",
    "        total_weights = 0.0\n",
    "        total_weighted_dev = 0.0\n",
    "        for neighbor in self.weight_heapqs[user_id]:\n",
    "            total_weights += abs(neighbor.value)\n",
    "            try:\n",
    "                dev = self.movie_devs[neighbor.name][movie_id]\n",
    "                total_weighted_dev += neighbor.value * dev\n",
    "            except KeyError:\n",
    "                continue\n",
    "\n",
    "        if total_weights != 0:\n",
    "            return self.means[user_id] + total_weighted_dev / total_weights\n",
    "        else:\n",
    "            return self.means[user_id]\n",
    "\n",
    "    def predict(self):\n",
    "        self.predicted_results = [{} for _ in range(len(self.weight_heapqs))]\n",
    "        for _, row in train_df.iterrows():\n",
    "            user_id, movie_id = int(row.userId), int(row.movieId)\n",
    "            predicted_rating = self._predict(user_id=user_id, movie_id=movie_id)\n",
    "            self.predicted_results[user_id][movie_id] = predicted_rating\n",
    "\n",
    "\n",
    "t = User2UserTraining()  \n",
    "t.initialize_model()\n",
    "# t.train()\n",
    "t.predict()\n",
    "\n",
    "for user_id, predictions in enumerate(t.predicted_results):\n",
    "    if predictions:\n",
    "        for movie_id, prediction in predictions.items():\n",
    "            #TODO Remember to remove\n",
    "            print(f'User {user_id} actual: {ratings[(user_id, movie_id)]}, predicted: {prediction}, avg {t.means[user_id]}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "import numpy as np\n",
    "from typing import Set\n",
    "import heapq\n",
    "import time\n",
    "\n",
    "NEIGHBOR_NUM = 25\n",
    "# threshold on number of movies for neightbors\n",
    "COMMON_MOVIE_THRE = 5\n",
    "DEBUG_USER_THRE = 3\n",
    "Weight = namedtuple(\"Weight\",[\"value\", \"name\"])\n",
    "\n",
    "class Item2ItemTraining:\n",
    "    def __init__(self):\n",
    "        print(f'Loading Training model')\n",
    "        self.training_results_path = os.path.join(movie_lens_path, \"item2item_training_results.pkl\")\n",
    "        self.training_results_index = 1\n",
    "        self.debug_count = 0\n",
    "        self.loaded_objs = []\n",
    "\n",
    "    def initialize_model(self):\n",
    "        for i in range(self.training_results_index, 0, -1):\n",
    "            training_results_path = self.training_results_path + \".\" + str(i)\n",
    "            with open(training_results_path, \"rb\") as f:\n",
    "                while True:\n",
    "                    try:\n",
    "                        self.loaded_objs.append(pickle.load(f))\n",
    "                    except EOFError:\n",
    "                        break \n",
    "            \n",
    "            if self.loaded_objs:\n",
    "                self.weight_heapqs, self.means, self.stds, self.movie_devs, self.compared = self.loaded_objs\n",
    "                print(f'Training model loaded successfully, from {training_results_path}')\n",
    "                return \n",
    "\n",
    "        # User data are stored in lists, because the indices have been normalized\n",
    "        self.weight_heapqs = [[Weight(float('-inf'), \"\") for _ in range(NEIGHBOR_NUM)] for _ in range (len(user2movies))] \n",
    "        self.means = [float('-inf') for _ in range (len(user2movies))] \n",
    "        self.stds = [float('-inf') for _ in range (len(user2movies))] \n",
    "        # deviations of each user. A movie deviation is rating - mean\n",
    "        self.movie_devs = [{} for _ in range (len(user2movies))]\n",
    "        # set that stores frozenset(user_i, user_i')\n",
    "        self.compared = set()\n",
    "        print(f'No training model found, initialized model objects')\n",
    "\n",
    "    def save_model(self):\n",
    "        \"\"\"\n",
    "        Save the model to different files: PATH.0, PATH.1\n",
    "        \"\"\"\n",
    "        if self.training_results_index % 2 == 0:\n",
    "            self.training_results_index = 0\n",
    "        training_results_path = self.training_results_path+\".\"+str(self.training_results_index)\n",
    "        with open(training_results_path, \"wb\") as f:\n",
    "            for obj in self.weight_heapqs, self.means, self.stds, self.movie_devs, self.compared:\n",
    "                pickle.dump(obj, f)\n",
    "        self.training_results_index += 1  \n",
    "\n",
    "    def get_and_update_mean_std(self,user: int, movies: Set[int]):\n",
    "        \"\"\"Update means and stds, and return them. Nice\"\"\"\n",
    "        if self.means[user] == float('-inf') or self.stds[user] != float('-inf'):\n",
    "            user_all_ratings = np.array([\n",
    "                ratings[(int(user), int(movie_id))] for movie_id in movies])\n",
    "            self.means[user] = np.mean(user_all_ratings)\n",
    "            # standard deviation of all user ratings\n",
    "            self.stds[user] = np.std(user_all_ratings)\n",
    "        return self.means[user], self.stds[user]\n",
    "\n",
    "    def get_and_update_movie_devs(self, mean: int, user: int, movies: Set[int]):\n",
    "        \"\"\"Update movie deviations for a single user. A movie deviation is rating - mean\"\"\"\n",
    "        if not self.movie_devs[user]:\n",
    "            user_all_ratings = np.array([\n",
    "                ratings[(int(user), int(movie_id))] for movie_id in movies])\n",
    "            dev_ratings = user_all_ratings - mean\n",
    "            self.movie_devs[user] = {movie: dev_rating for movie, dev_rating in zip(movies, dev_ratings)}\n",
    "        return self.movie_devs[user]\n",
    "\n",
    "    def has_been_trained(self, user: int):\n",
    "        \"\"\"\n",
    "        We are using self.movie_devs to check if a user's model has been trained. \n",
    "        Since the kernel might be killed accidentally, this function might return true on the last user that kernel broke. \n",
    "        But technically, that should be only one user.\n",
    "        \"\"\"\n",
    "        if self.movie_devs[user]:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def train(self):\n",
    "        start_time = time.perf_counter()\n",
    "        for user, movies in user2movies.items():\n",
    "            if self.debug_count % 10 == 0:\n",
    "                self.save_model()\n",
    "                print(f\"User count: {self.debug_count}, time elapsed: {time.perf_counter() - start_time}s\")\n",
    "            self.debug_count += 1\n",
    "            if self.has_been_trained(user):\n",
    "                continue\n",
    "            mean, std = self.get_and_update_mean_std(user, movies)\n",
    "            movie_devs_dict = self.get_and_update_movie_devs(mean, user, movies)\n",
    "            for movie_id in movies:\n",
    "                other_users = movies2user[movie_id]\n",
    "                for another_user in other_users:\n",
    "                    # See if we have compared \n",
    "                    key_compared = frozenset((user, another_user))\n",
    "                    if key_compared in self.compared:\n",
    "                        continue\n",
    "                    self.compared.add(key_compared)\n",
    "                    another_user_movies = user2movies[another_user]\n",
    "                    common_movies = movies & another_user_movies\n",
    "\n",
    "                    if len(common_movies) < COMMON_MOVIE_THRE:\n",
    "                        continue\n",
    "\n",
    "                    if another_user == user:\n",
    "                        continue \n",
    "                    # calculate weight: \n",
    "                    # HACK: we are calculating weights using the stds and movie_devs of all users' movies, instead of the common ones\n",
    "                    # Then, a weight is calculated by multiplying sums of deviations of the common movies\n",
    "                    # That's been tested fine in production. So, this may not work great if the common movie's std deviations are drastically\n",
    "                    # different from the two users over standard deviation \n",
    "                    another_mean, another_std = self.get_and_update_mean_std(another_user, another_user_movies)\n",
    "                    another_movie_devs_dict = self.get_and_update_movie_devs(another_mean, another_user, another_user_movies)\n",
    "                    numerator = sum([movie_devs_dict[m] * another_movie_devs_dict[m] for m in common_movies])/len(common_movies)\n",
    "                    denominator = another_std * std\n",
    "\n",
    "                    if denominator != 0.0:\n",
    "                        w_ij = numerator/denominator\n",
    "\n",
    "                    # add to heapque\n",
    "                    heapq.heappushpop(self.weight_heapqs[user], Weight(w_ij, another_user))\n",
    "                    heapq.heappushpop(self.weight_heapqs[another_user], Weight(w_ij, user))\n",
    "\n",
    "    def _predict(self, user_id: int, movie_id: int):\n",
    "        total_weights = 0.0\n",
    "        total_weighted_dev = 0.0\n",
    "        for neighbor in self.weight_heapqs[user_id]:\n",
    "            total_weights += abs(neighbor.value)\n",
    "            try:\n",
    "                dev = self.movie_devs[neighbor.name][movie_id]\n",
    "                total_weighted_dev += neighbor.value * dev\n",
    "            except KeyError:\n",
    "                continue\n",
    "\n",
    "        if total_weights != 0:\n",
    "            return self.means[user_id] + total_weighted_dev / total_weights\n",
    "        else:\n",
    "            return self.means[user_id]\n",
    "\n",
    "    def predict(self):\n",
    "        self.predicted_results = [{} for _ in range(len(self.weight_heapqs))]\n",
    "        for _, row in train_df.iterrows():\n",
    "            user_id, movie_id = int(row.userId), int(row.movieId)\n",
    "            predicted_rating = self._predict(user_id=user_id, movie_id=movie_id)\n",
    "            self.predicted_results[user_id][movie_id] = predicted_rating\n",
    "\n",
    "\n",
    "t = User2UserTraining()  \n",
    "t.initialize_model()\n",
    "# t.train()\n",
    "t.predict()\n",
    "\n",
    "for user_id, predictions in enumerate(t.predicted_results):\n",
    "    if predictions:\n",
    "        for movie_id, prediction in predictions.items():\n",
    "            #TODO Remember to remove\n",
    "            print(f'User {user_id} actual: {ratings[(user_id, movie_id)]}, predicted: {prediction}, avg {t.means[user_id]}') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TUTORIALS\n",
    "# accessing a column\n",
    "df[\"rating\"]\n",
    "df.rating\n",
    "# how to filter\n",
    "df[df.rating == 3.0]\n",
    "# You need to specify which axis to drop. by default 0 (row), 1 for column, \n",
    "# df.drop(\"timestamp\", axis=1)\n",
    "# length of dataframe\n",
    "print(f\"length of dataframe: {len(df)}\")\n",
    "# access integer clns:\n",
    "print(f\"integer access: {df.iloc[2]}\")\n",
    "\n",
    "\n",
    "# subtract a number from the column: \n",
    "df.userId - 1\n",
    "# count common occurences:\n",
    "from collections import Counter\n",
    "counter_set = Counter([1,2,2,3,3])\n",
    "common_user_ids = counter_set.most_common(2)\n",
    "print(f'Rico, common_user_ids: {common_user_ids}')\n",
    "test_pd = pd.DataFrame([u for u,c in common_user_ids], columns=[\"test_column\"])\n",
    "print(f'Rico, pd dataframe common_user_ids: {common_user_ids}')\n",
    "\n",
    "# select rows based on 2 conditions: \n",
    "df[df.userId.isin(common_user_ids) & df.movieId.isin(common_user_ids)]\n",
    "\n",
    "# shuffle a list / dataframe\n",
    "from sklearn.utils import shuffle\n",
    "ls = shuffle([1,2,3,4,5])\n",
    "#TODO Remember to remove\n",
    "print(f'Rico: shuffled ls: {ls}')\n",
    "\n",
    "# named tiple\n",
    "from collections import namedtuple\n",
    "Subscriber = namedtuple(\"some_name\", [\"addr\", \"name\"])\n",
    "sub = Subscriber(\"123 st\", \"Jo\")\n",
    "sub_new = sub._replace(addr=\"456st\")\n",
    "print(\"field: \", sub_new.addr) \n",
    "print(sub, sub_new)\n",
    "print(\"converted to dictionary: \", sub_new._asdict())\n",
    "# like tuple, after construction, cannot be modified\n",
    "# sub.name = 30\n",
    "# print(f'sub after change: {sub}')\n",
    "#TODO Remember to remove\n",
    "print(f'named_tuples can also be accessed through indexing: {sub[0]}')\n",
    "\n",
    "\n",
    "# heapq\n",
    "li = [Subscriber(0, \"NULL\")]*5\n",
    "import heapq\n",
    "for i in range(1, 7):\n",
    "    heapq.heappush(li, Subscriber(i, \"Rico\"+str(i)))\n",
    "    heapq.heappop(li)\n",
    "# This way to make sure small value is popped \n",
    "heapq.heappushpop(li, Subscriber(1, \"Rico1\"))\n",
    "print(f'{li}')\n",
    "\n",
    "#TODO Remember to remove\n",
    "print(f'smallest int: {float(\"-inf\")}')\n",
    "\n",
    "#dictionary length:\n",
    "di = {1:2, 3:4, 5:6}\n",
    "#TODO Remember to remove\n",
    "print(f'len(di): {len(di)}')\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
